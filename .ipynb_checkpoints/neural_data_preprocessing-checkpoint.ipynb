{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/SteinwayThor/eeg-features-movies/blob/main/neural_data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dsv_qhY0cypE"
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "#from google.colab import drive\n",
    "import bz2\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUJJmujzctmx",
    "outputId": "4d84f23d-62cb-4106-ba95-622fe0689678"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Load any compressed pickle file\n",
    "def decompress_pickle(file):\n",
    "  data = bz2.BZ2File(file, 'rb')\n",
    "  data = cPickle.load(data)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "FjIogycqxzpw"
   },
   "outputs": [],
   "source": [
    "neural_data_folder = '../raw_eeg'\n",
    "neural_data_dir = os.listdir(neural_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "rDCSvkXAxwk0"
   },
   "outputs": [],
   "source": [
    "#Extract start and end of chapters:\n",
    "events_f = [f for f in neural_data_dir if 'events' in f.lower()][0]\n",
    "events = decompress_pickle(os.path.join(neural_data_folder, events_f))\n",
    "chapter_idx = [event for event in events['signal'] if event[0]==9 or event[0]==18]\n",
    "start_stop = [(chapter_idx[i][1],chapter_idx[i+1][1]) for i in range(0,len(chapter_idx), 2)]\n",
    "chapter_idx = dict(zip((range(1,len(start_stop)+1)),start_stop))\n",
    "del events, start_stop, events_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vb7ZlaPu0EVq",
    "outputId": "9d7f8c13-3512-4a3e-95d1-800a289d1c82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (23828108, 24179424),\n",
       " 2: (24181586, 24557675),\n",
       " 3: (24558933, 24956256),\n",
       " 4: (24957529, 25294656),\n",
       " 5: (25295943, 25593803),\n",
       " 6: (25595013, 25965313),\n",
       " 7: (25966462, 26370719),\n",
       " 8: (26371896, 26711407),\n",
       " 9: (26712625, 27178388),\n",
       " 10: (27179752, 27695292),\n",
       " 11: (27696813, 28188900),\n",
       " 12: (28190842, 28532606),\n",
       " 13: (28533966, 29040089),\n",
       " 14: (29041771, 29418395),\n",
       " 15: (29419847, 29804615),\n",
       " 16: (29806140, 30300732),\n",
       " 17: (30302312, 30687636),\n",
       " 18: (30689435, 30901312),\n",
       " 19: (30902789, 31380891),\n",
       " 20: (31382496, 31449857)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFxRf8Yu6-7O",
    "outputId": "ccca49b1-28dd-4557-fdc4-616c09bb680a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chapter_idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADImcvQV7GCM"
   },
   "outputs": [],
   "source": [
    "#find all channels:\n",
    "channels = ['RPH14', 'RPH13', 'RPH12', 'RPH11', 'RPH10', 'RPH9', 'RPH8', 'RPH7', 'RPH6', 'RPH5', 'RPH4', 'RPH3', 'RPH2', 'RPH1', 'RAH14', 'RAH13', 'RAH12', 'RAH11', 'RAH10', 'RAH9', 'RAH8', 'RAH7', 'RAH6', 'RAH5', 'RAH4', 'RAH3', 'RAH2', 'RAH1', 'RAMY14', 'RAMY13', 'RAMY12', 'RAMY11', 'RAMY10', 'RAMY9', 'RAMY8', 'RAMY7', 'RAMY6', 'RAMY5', 'RAMY4', 'RAMY3', 'RAMY2', 'RAMY1', 'LPH14', 'LPH13', 'LPH12', 'LPH11', 'LPH10', 'LPH9', 'LPH8', 'LPH7', 'LPH6', 'LPH5', 'LPH4', 'LPH3', 'LPH2', 'LPH1', 'LAH14', 'LAH13', 'LAH12', 'LAH11', 'LAH10', 'LAH9', 'LAH8', 'LAH7', 'LAH6', 'LAH5', 'LAH4', 'LAH3', 'LAH2', 'LAH1', 'LAMY14', 'LAMY13', 'LAMY12', 'LAMY11', 'LAMY10', 'LAMY9', 'LAMY8', 'LAMY7', 'LAMY6', 'LAMY5', 'LAMY4', 'LAMY3', 'LAMY2', 'LAMY1']\n",
    "'''\n",
    "for f in neural_data_dir:\n",
    "    if (not '.pbz' in f.lower()) or ('event' in f.lower()):\n",
    "      continue\n",
    "    channel_name = f[f.rfind('_')+1:-5]\n",
    "    channels.append(channel_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKaPUNA67TEq",
    "outputId": "5b6c4737-1b73-4b21-e9fc-51fc10437712"
   },
   "outputs": [],
   "source": [
    "channels_dict = dict((i,[]) for i in channels)\n",
    "del channels\n",
    "channels_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atI8rtrFeo4V"
   },
   "outputs": [],
   "source": [
    "#!rm -rf  don't run this command unless /content/drive/MyDrive/'Movie Data'/EEG_chapters\n",
    "!mkdir /content/drive/MyDrive/'Movie Data'/EEG_chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7yAoP5KcofU",
    "outputId": "ca43cac8-9721-4c59-f327-6ff7926d1f43",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load in neural data\n",
    "# NOTE: Takes a while!\n",
    "#chapter_idx\n",
    "eeg_chapter_path = '/content/drive/MyDrive/Movie Data/EEG_chapters/'\n",
    "\n",
    "for f in neural_data_dir:\n",
    "  if (not '.pbz' in f.lower()) or ('event' in f.lower()):\n",
    "        continue\n",
    "  channel_name = f[f.rfind('_')+1:-5]\n",
    "  channel_data = decompress_pickle(os.path.join(neural_data_folder, f))['signal']\n",
    "  gc.collect()\n",
    "  for chapter in chapter_idx:\n",
    "    with open(eeg_chapter_path + 'chapter_' + str(chapter).zfill(2) + '_' + channel_name + '.json', 'w') as fp:\n",
    "      json.dump({channel_name: channel_data[chapter_idx[chapter][0]:chapter_idx[chapter][1]].tolist()}, fp, indent=2)\n",
    "  del channel_data\n",
    "  gc.collect()\n",
    "  print(\"Processed channel\", channel_name, \"and all chapters.\")\n",
    "  print(\"---------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3rLH2ytD-xT"
   },
   "outputs": [],
   "source": [
    "total_channels = len(list(channels_dict.keys()))\n",
    "chapters = dict(zip(list(chapter_idx.keys()), [[] for i in range(20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSVFjBuxjVpJ"
   },
   "outputs": [],
   "source": [
    "eeg_chapter_path = '/content/drive/MyDrive/Movie Data/EEG_chapters/'\n",
    "for file_ in os.listdir(eeg_chapter_path):\n",
    "  chapters[int(file_.split('_')[1])].append(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmWH_EdCESoa",
    "outputId": "3f5573b8-cefb-471f-82d8-9635fd8755a6"
   },
   "outputs": [],
   "source": [
    "!du -hs /content/drive/MyDrive/'Movie Data'/EEG_chapters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XagLVvynDOdf"
   },
   "outputs": [],
   "source": [
    "for chapter in chapters:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here the code is made for local machine and my particular environment, it might not work on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find missing files per channel of eeg\n",
    "missing_chapter = dict(zip(channels, ([] for i in range(len(channels)))))\n",
    "all_eeg = '../all_eeg'\n",
    "for file_ in os.listdir(all_eeg): \n",
    "    missing_chapter[file_.split('_')[2][:-5]].append(int(file_.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chapter = set(range(1,21))\n",
    "for channel in missing_chapter:     \n",
    "    missing_chapter[channel] = list(all_chapter - set(missing_chapter[channel]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_chapter = dict((i,missing_chapter[i]) for i in missing_chapter if len(missing_chapter[i])>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LAH8', 'LAH7', 'LAH6', 'LAH5', 'LAH4', 'LAH3', 'LAH2', 'LAH1', 'LAMY14', 'LAMY13', 'LAMY12', 'LAMY11', 'LAMY10', 'LAMY9', 'LAMY8', 'LAMY7', 'LAMY6', 'LAMY5', 'LAMY4', 'LAMY3', 'LAMY2', 'LAMY1'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_chapter.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "MvX_UNx4FFEI"
   },
   "outputs": [],
   "source": [
    "all_eeg = '../all_eeg'\n",
    "raw_eeg = '../raw_eeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "set() 0\n"
     ]
    }
   ],
   "source": [
    "required = set(list(missing_chapter.keys()))\n",
    "print(len(required))\n",
    "for f in os.listdir(raw_eeg): \n",
    "    if (not '.pbz' in f.lower()): \n",
    "        continue\n",
    "    channel_name = f.split('_')[2][:-5]\n",
    "    required = required-{channel_name}\n",
    "print(required, len(required))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_chapter_path = '../all_eeg/'\n",
    "for f in os.listdir(raw_eeg):\n",
    "    if (not '.pbz' in f.lower()) or ('event' in f.lower()):\n",
    "        continue\n",
    "    channel_name = f[f.rfind('_')+1:-5]\n",
    "    if (not channel_name in list(missing_chapter.keys())): \n",
    "        continue\n",
    "    channel_data = decompress_pickle(os.path.join(neural_data_folder, f))['signal']\n",
    "    gc.collect()\n",
    "    for chapter in missing_chapter[channel_name]:\n",
    "        with open(eeg_chapter_path + 'chapter_' + str(chapter).zfill(2) + '_' + channel_name + '.json', 'w') as fp:\n",
    "            json.dump({channel_name: channel_data[chapter_idx[chapter][0]:chapter_idx[chapter][1]].tolist()}, fp, indent=2)\n",
    "    del channel_data\n",
    "    gc.collect()\n",
    "    print(\"Processed channel\", channel_name, \"and all chapters.\")\n",
    "    print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
